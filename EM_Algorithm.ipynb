{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07be473b",
   "metadata": {},
   "source": [
    "# EM ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb577a",
   "metadata": {},
   "source": [
    "##### DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92609dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = ['Athletics',\n",
    " 'Archery',\n",
    " 'Badminton',\n",
    " 'Baseball',\n",
    " 'Basketball',\n",
    " 'Bobsleigh',\n",
    " 'Bowling',\n",
    " 'Boxing',\n",
    " 'Canoeing',\n",
    " 'Cycling',\n",
    " 'Climbing',\n",
    " 'Cricket',\n",
    " 'Diving',\n",
    " 'Equestrian',\n",
    " 'Fencing',\n",
    " 'Fishing',\n",
    " 'Football',\n",
    " 'Golf',\n",
    " 'Gymnastics',\n",
    " 'Handball',\n",
    " 'Hiking',\n",
    " 'Hockey',\n",
    " 'Hunting',\n",
    " 'Judo',\n",
    " 'Karate',\n",
    " 'Kayaking',\n",
    " 'Lacrosse',\n",
    " 'Motorsports',\n",
    " 'Paddleboarding',\n",
    " 'Paintball',\n",
    " 'Paragliding',\n",
    " 'Powerlifting',\n",
    " 'Rafting',\n",
    " 'Rockclimbing',\n",
    " 'Rowing',\n",
    " 'Rugby',\n",
    " 'Running',\n",
    " 'Sailing',\n",
    " 'Shooting',\n",
    " 'Skateboarding',\n",
    " 'Skating',\n",
    " 'Skeetshooting',\n",
    " 'Skiing',\n",
    " 'Skydiving',\n",
    " 'Snowboarding',\n",
    " 'Soccer',\n",
    " 'Squash',\n",
    " 'Surfcasting',\n",
    " 'Surfing',\n",
    " 'Swimming',\n",
    " 'Note',\n",
    " 'Chord',\n",
    " 'Harmony',\n",
    " 'Melody',\n",
    " 'Rhythm',\n",
    " 'Beat',\n",
    " 'Tempo',\n",
    " 'Pitch',\n",
    " 'Key',\n",
    " 'Scale',\n",
    " 'Interval',\n",
    " 'Tune',\n",
    " 'Composition',\n",
    " 'Song',\n",
    " 'Lyrics',\n",
    " 'Instrument',\n",
    " 'Piano',\n",
    " 'Guitar',\n",
    " 'Bass',\n",
    " 'Drums',\n",
    " 'Violin',\n",
    " 'Cello',\n",
    " 'Trumpet',\n",
    " 'Saxophone',\n",
    " 'Clarinet',\n",
    " 'Flute',\n",
    " 'Harp',\n",
    " 'Accordion',\n",
    " 'Banjo',\n",
    " 'Mandolin',\n",
    " 'Ukulele',\n",
    " 'Harmonica',\n",
    " 'Synthesizer',\n",
    " 'Sampler',\n",
    " 'Mixer',\n",
    " 'DJ',\n",
    " 'Producer',\n",
    " 'Conductor',\n",
    " 'Singer',\n",
    " 'Vocalist',\n",
    " 'Backing Singer',\n",
    " 'Choir',\n",
    " 'Ensemble',\n",
    " 'Band',\n",
    " 'Soloist',\n",
    " 'Improvisation',\n",
    " 'Jazz',\n",
    " 'Blues',\n",
    " 'Rock',\n",
    " 'Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = [word.lower() for word in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = np.array(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1413899",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76c212",
   "metadata": {},
   "source": [
    "##### MOST PROBABLE WORDS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b113eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def most_probable_words(words, probabilities):\n",
    "    # create a DataFrame from the words and probabilities\n",
    "    df = pd.DataFrame({'word': words, 'probability': probabilities})\n",
    "    \n",
    "    # sort by probability in descending order\n",
    "    df_sorted = df.sort_values(by='probability', ascending=False)\n",
    "    \n",
    "    # get the top 10 words\n",
    "    top_10_words = df_sorted.head(10)['word'].values\n",
    "    \n",
    "    return list(top_10_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56fccf",
   "metadata": {},
   "source": [
    "## RELOADING ORIGINAL DISTRIBUTIONS OVER WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ed92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the data from the CSV file\n",
    "loaded_data = np.loadtxt(\"beta_original.csv\", delimiter=\",\")\n",
    "\n",
    "b_sport = loaded_data[:, 0]  # First column\n",
    "b_music = loaded_data[:, 1]  # Second column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3e847",
   "metadata": {},
   "source": [
    "## RELOADING DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a558b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "short_dtm = pd.read_csv('short_dtm.csv')\n",
    "# Convert the DataFrame to a matrix if needed\n",
    "#short_dtm = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caa1ce",
   "metadata": {},
   "source": [
    "# EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_algorithm(data_matrix, max_iter=300, param_tol=1e-20, likelihood_tol=1e-5, moving_avg_window=50):\n",
    "    D, V = data_matrix.shape \n",
    "\n",
    "    # initialize parameters randomly\n",
    "    pi = 0.5\n",
    "    beta = np.random.rand(2, V)\n",
    "    beta /= np.sum(beta, axis=1)[:, np.newaxis]\n",
    "\n",
    "    log_likelihoods = []\n",
    "\n",
    "    # Store initial values to calculate rate of change\n",
    "    old_pi = pi\n",
    "    old_beta = beta.copy()\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "    # EXPECTATION\n",
    "        \n",
    "        # Initializes an empty 2D array p_z with D rows and 2 columns. D represents the number of documents \n",
    "        # in the dataset. \n",
    "        # p_z will store the probability of each document belonging to each of the two clusters (topics).\n",
    "        \n",
    "        p_z = np.zeros((D, 2)) \n",
    "        p_z[:, 0] = pi * np.prod(beta[0]**data_matrix, axis=1)\n",
    "        p_z[:, 1] = (1 - pi) * np.prod(beta[1]**data_matrix, axis=1)\n",
    "        \n",
    "                # beta[0] is selecting the first row of the beta matrix, which represents the probabilities \n",
    "                # of each word given topic 1. **data_matrix is applying element-wise exponentiation of beta[0] \n",
    "                # with each document in the data_matrix. np.prod(..., axis=1) is then calculating the product \n",
    "                # of these probabilities along axis=1, which represents the words (the columns of data_matrix). \n",
    "                # For each document (each row of data_matrix), it's calculating the product of the \n",
    "                # probabilities of the words in that document.\n",
    "        \n",
    "        p_z /= np.sum(p_z, axis=1)[:, np.newaxis] # normalize\n",
    "\n",
    "    # MAXIMIZATION\n",
    "        \n",
    "        # Calculating the average of the posterior probabilities of each document belonging to class 1      \n",
    "        pi = np.mean(p_z[:, 0]) \n",
    "        \n",
    "        for k in range(2):\n",
    "            for v in range(V): \n",
    "                \n",
    "                # Updates each entry in beta\n",
    "                # Calculating the sum of the product of the posterior probabilities of each document having \n",
    "                # topic k and the count of word v in each document.\n",
    "                beta[k, v] = np.sum(p_z[:, k] * data_matrix[:, v]) \n",
    "            beta[k] /= np.sum(beta[k])  # normalize \n",
    "                                        # dividing each entry in the kth row of beta by the sum of that row.\n",
    "\n",
    "\n",
    "        # Compute log likelihood and add to list\n",
    "        log_likelihood = np.sum(p_z[:, 0]*np.log(pi * np.prod(beta[0]**data_matrix, axis=1) + 1e-10) +\n",
    "                                p_z[:, 1]*np.log((1 - pi) * np.prod(beta[1]**data_matrix, axis=1) + 1e-10))\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "\n",
    "        # Initialize convergence count\n",
    "        convergence_count = 0\n",
    "        \n",
    "        # Paramater convergence\n",
    "        param_converged = i > 0 and np.abs(pi - old_pi) < param_tol and np.linalg.norm(beta - old_beta) < param_tol\n",
    "\n",
    "        # Check for convergence using difference in log likelihoods\n",
    "        likelihood_converged = i > 0 and np.abs(log_likelihoods[i] - log_likelihoods[i-1]) < likelihood_tol\n",
    "        \n",
    "        # If both conditions are satisfied, break the loop\n",
    "        if param_converged and likelihood_converged:\n",
    "            print(f'Converged at iteration {i}')\n",
    "            break\n",
    "\n",
    "        # Store old values for next iteration\n",
    "        old_pi = pi\n",
    "        old_beta = beta.copy()\n",
    "            \n",
    "    return pi, beta, log_likelihoods\n",
    "\n",
    "# Load data\n",
    "data_matrix = short_dtm\n",
    "\n",
    "# Convert DataFrame to NumPy array before passing to EM_algorithm\n",
    "data_matrix_np = data_matrix.to_numpy()\n",
    "\n",
    "# Run EM\n",
    "pi, beta, log_likelihoods = EM_algorithm(data_matrix_np)\n",
    "\n",
    "\n",
    "# Print beta_1, beta_2, and pi_1\n",
    "print(\"Beta 1: \", beta[0])\n",
    "print(\"Beta 2: \", beta[1])\n",
    "print(\"Pi 1: \", pi)\n",
    "\n",
    "# Plot betas\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(beta[0], label='Beta 1')\n",
    "plt.plot(beta[1], label='Beta 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442bd1b",
   "metadata": {},
   "source": [
    "###### MOST PROBABLE WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b443ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_probable_words(dictionary, beta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13269108",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_probable_words(dictionary, beta[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
