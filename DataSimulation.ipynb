{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07be473b",
   "metadata": {},
   "source": [
    "# SIMULATING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb577a",
   "metadata": {},
   "source": [
    "## DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92609dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = ['Athletics',\n",
    " 'Archery',\n",
    " 'Badminton',\n",
    " 'Baseball',\n",
    " 'Basketball',\n",
    " 'Bobsleigh',\n",
    " 'Bowling',\n",
    " 'Boxing',\n",
    " 'Canoeing',\n",
    " 'Cycling',\n",
    " 'Climbing',\n",
    " 'Cricket',\n",
    " 'Diving',\n",
    " 'Equestrian',\n",
    " 'Fencing',\n",
    " 'Fishing',\n",
    " 'Football',\n",
    " 'Golf',\n",
    " 'Gymnastics',\n",
    " 'Handball',\n",
    " 'Hiking',\n",
    " 'Hockey',\n",
    " 'Hunting',\n",
    " 'Judo',\n",
    " 'Karate',\n",
    " 'Kayaking',\n",
    " 'Lacrosse',\n",
    " 'Motorsports',\n",
    " 'Paddleboarding',\n",
    " 'Paintball',\n",
    " 'Paragliding',\n",
    " 'Powerlifting',\n",
    " 'Rafting',\n",
    " 'Rockclimbing',\n",
    " 'Rowing',\n",
    " 'Rugby',\n",
    " 'Running',\n",
    " 'Sailing',\n",
    " 'Shooting',\n",
    " 'Skateboarding',\n",
    " 'Skating',\n",
    " 'Skeetshooting',\n",
    " 'Skiing',\n",
    " 'Skydiving',\n",
    " 'Snowboarding',\n",
    " 'Soccer',\n",
    " 'Squash',\n",
    " 'Surfcasting',\n",
    " 'Surfing',\n",
    " 'Swimming',\n",
    " 'Note',\n",
    " 'Chord',\n",
    " 'Harmony',\n",
    " 'Melody',\n",
    " 'Rhythm',\n",
    " 'Beat',\n",
    " 'Tempo',\n",
    " 'Pitch',\n",
    " 'Key',\n",
    " 'Scale',\n",
    " 'Interval',\n",
    " 'Tune',\n",
    " 'Composition',\n",
    " 'Song',\n",
    " 'Lyrics',\n",
    " 'Instrument',\n",
    " 'Piano',\n",
    " 'Guitar',\n",
    " 'Bass',\n",
    " 'Drums',\n",
    " 'Violin',\n",
    " 'Cello',\n",
    " 'Trumpet',\n",
    " 'Saxophone',\n",
    " 'Clarinet',\n",
    " 'Flute',\n",
    " 'Harp',\n",
    " 'Accordion',\n",
    " 'Banjo',\n",
    " 'Mandolin',\n",
    " 'Ukulele',\n",
    " 'Harmonica',\n",
    " 'Synthesizer',\n",
    " 'Sampler',\n",
    " 'Mixer',\n",
    " 'DJ',\n",
    " 'Producer',\n",
    " 'Conductor',\n",
    " 'Singer',\n",
    " 'Vocalist',\n",
    " 'Backing Singer',\n",
    " 'Choir',\n",
    " 'Ensemble',\n",
    " 'Band',\n",
    " 'Soloist',\n",
    " 'Improvisation',\n",
    " 'Jazz',\n",
    " 'Blues',\n",
    " 'Rock',\n",
    " 'Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b72657",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = [word.lower() for word in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = np.array(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1413899",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56fccf",
   "metadata": {},
   "source": [
    "## TOPICS - DISTRIBUTION OVER WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c65cc",
   "metadata": {},
   "source": [
    "Topic is a distribution over words, so now we will make two vectors that represents two distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b593995e",
   "metadata": {},
   "source": [
    "### SPORT DISTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694f4e6",
   "metadata": {},
   "source": [
    "90% probability is on first 10 words\n",
    "\n",
    "The scale parameter, betha = 1 / lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an array of 10 random numbers from an exponential distribution, normalized so it sums to .9\n",
    "exp_array = np.random.exponential(1, size=10)\n",
    "ten = (exp_array / np.sum(exp_array)) * 0.9\n",
    "\n",
    "# an array of 90 random numbers from an exponential distribution, normalized so it sums to .1\n",
    "exp_array = np.random.exponential(1, size=90)\n",
    "ninety = (exp_array / np.sum(exp_array)) * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77314a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten.sum(), ninety.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f90087",
   "metadata": {},
   "source": [
    "##### Check that it sums to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b8221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sport = np.concatenate([ten, ninety])\n",
    "b_sport.sum()\n",
    "#sport_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5019360",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(b_sport )), b_sport, marker='o')\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('sport_distribution')\n",
    "plt.xlabel('Position in the words vector')\n",
    "plt.ylabel('Probability that the word will occur')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123f8d3",
   "metadata": {},
   "source": [
    "### MUSIC DISTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a12e8",
   "metadata": {},
   "source": [
    "90% of probability is on last 10 words in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abef5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an array of 90 random numbers from an exponential distribution, normalized so it sums to .1\n",
    "exp_array = np.random.exponential(1, size=90)\n",
    "eighty = (exp_array / np.sum(exp_array)) * 0.1\n",
    "\n",
    "# an array of 10 random numbers from an exponential distribution, normalized so it sums to .9\n",
    "exp_array = np.random.exponential(1, size=10)\n",
    "twenty = (exp_array / np.sum(exp_array)) * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44265d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "eighty.sum(),twenty.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f1e74",
   "metadata": {},
   "source": [
    "##### Check that it sums to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c97723",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_music = np.concatenate([eighty, twenty])\n",
    "b_music.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6802529",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3034d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(b_music)), b_music, marker='o')\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('music_distribution')\n",
    "plt.xlabel('Position in the words vector')\n",
    "plt.ylabel('Probability that the word will occur')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(b_music)), print(type(b_sport)), print(type(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8a0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot distribution_1 with a red color\n",
    "ax.plot(range(len(b_sport )), b_sport, 'r', label='Sport')\n",
    "\n",
    "# Plot distribution_2 with a blue color\n",
    "ax.plot(range(len(b_music)), b_music, 'b', label='Music')\n",
    "\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Index in Dictionary')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Probability Distributions')\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d51bb",
   "metadata": {},
   "source": [
    "##### MOST PROBABLE WORDS UNDER BOTH DISTRIBUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def most_probable_words(words, probabilities):\n",
    "    # create a DataFrame from the words and probabilities\n",
    "    df = pd.DataFrame({'word': words, 'probability': probabilities})\n",
    "    \n",
    "    # sort by probability in descending order\n",
    "    df_sorted = df.sort_values(by='probability', ascending=False)\n",
    "    \n",
    "    # get the top 10 words\n",
    "    top_10_words = df_sorted.head(10)['word'].values\n",
    "    \n",
    "    return list(top_10_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_probable_words(dictionary, b_sport )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd17449",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_probable_words(dictionary, b_music )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3e847",
   "metadata": {},
   "source": [
    "# GENERATING DOCUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45840d2a",
   "metadata": {},
   "source": [
    "150 document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = ['Sport', 'Music'] \n",
    "phi = [0.3, 0.7]\n",
    "n = 100 # number of words per document\n",
    "\n",
    "\n",
    "# Empty list for generated documents\n",
    "documents = []\n",
    "\n",
    "\n",
    "for i in range(150):\n",
    "    # Choose a topic \n",
    "    chosen_topic = np.random.choice(K, p = phi)\n",
    "\n",
    "    if chosen_topic == 'Sport':\n",
    "        chosen_probs = b_sport \n",
    "    else:\n",
    "        chosen_probs = b_music\n",
    "\n",
    "    doc_words = [np.random.choice(dictionary, p=chosen_probs) for j in range(n)]   \n",
    "    doc_string = ' '.join(doc_words)   \n",
    "    documents.append(doc_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d18e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b0f40",
   "metadata": {},
   "source": [
    "1000 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62454f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = ['Sport', 'Music'] \n",
    "phi = [0.3, 0.7]\n",
    "n = 100 # number of words per document\n",
    "\n",
    "\n",
    "# Empty list for generated documents\n",
    "long_documents = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    # Choose a topic \n",
    "    chosen_topic = np.random.choice(K, p = phi)\n",
    "\n",
    "    if chosen_topic == 'Sport':\n",
    "        chosen_probs = b_sport \n",
    "    else:\n",
    "        chosen_probs = b_music\n",
    "\n",
    "    doc_words = [np.random.choice(dictionary, p=chosen_probs) for j in range(n)]   \n",
    "    doc_string = ' '.join(doc_words)   \n",
    "    long_documents.append(doc_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484652d",
   "metadata": {},
   "source": [
    "# DOCUMENT TERM MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef37c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba513b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "short = pd.DataFrame(documents, columns=['documents'])\n",
    "# Print DataFrame\n",
    "# print(short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "long = pd.DataFrame(long_documents, columns=['documents'])\n",
    "#print(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d3423",
   "metadata": {},
   "source": [
    "short DTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d48a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Learn the vocabulary dictionary and return document-term matrix.\n",
    "X = vectorizer.fit_transform(short['documents'])\n",
    "\n",
    "# Create a DataFrame\n",
    "short_dtm = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(short_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a9601",
   "metadata": {},
   "source": [
    "long DTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95756b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Learn the vocabulary dictionary and return document-term matrix.\n",
    "X = vectorizer.fit_transform(long['documents'])\n",
    "\n",
    "# Create a DataFrame\n",
    "long_dtm = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "print(long_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c1a10",
   "metadata": {},
   "source": [
    "Now we want to save both matrices and topics for further use in the EM alghorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed107e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(short_dtm)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('short_dtm.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(long_dtm)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('long_dtm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Combine the arrays. Here we stack them vertically using vstack\n",
    "combined_array = np.vstack((b_sport, b_music))\n",
    "\n",
    "# Transpose if you want each array as a column instead of a row\n",
    "combined_array = combined_array.T\n",
    "\n",
    "# Save to a CSV file\n",
    "np.savetxt(\"beta_original.csv\", combined_array, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
